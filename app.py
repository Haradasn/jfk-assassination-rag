import streamlit as st
from langchain_community.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from dotenv import load_dotenv
import os

load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

st.title("ğŸ“š JFK Document RAG Search")

query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if st.button("æ¤œç´¢"):
    vectorstore = Chroma(persist_directory="chroma_db", embedding_function=None)
    retriever = vectorstore.as_retriever()
    llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="map_reduce",
        retriever=retriever,
        return_source_documents=True
    )
    result = qa_chain({"query": query})

    st.subheader("ğŸ“Œ å›ç­”")
    st.write(result["result"])

    st.subheader("ğŸ“š å‚ç…§å…ƒ")
    for doc in result["source_documents"]:
        st.write(f"- {doc.metadata['source']}")